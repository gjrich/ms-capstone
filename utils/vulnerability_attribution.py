# vulnerability_attribution.py
import sqlite3
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import logging
import sys
import os

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('attribution_analysis.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

DB_PATH = 'data/vulnerability_analysis.db'
OUTPUT_DIR = 'analysis_results'

def prepare_data():
    """Extract and prepare data for attribute analysis."""
    conn = sqlite3.connect(DB_PATH)
    
    # Get data for predicting exploitation
    query = '''
    SELECT
        v.cve_id,
        v.cvss_v3_score,
        v.attack_vector,
        v.attack_complexity,
        v.privileges_required,
        v.user_interaction,
        v.scope,
        v.confidentiality_impact,
        v.integrity_impact,
        v.availability_impact,
        MAX(s.epss_score) AS max_epss_score,
        CASE WHEN COUNT(DISTINCT pe.id) > 0 THEN 1 ELSE 0 END AS has_public_exploit,
        CASE WHEN e.cve_id IS NOT NULL THEN 1 ELSE 0 END AS is_exploited
    FROM
        vulnerabilities v
    LEFT JOIN
        exploitations e ON v.cve_id = e.cve_id
    LEFT JOIN
        epss_scores s ON v.cve_id = s.cve_id
    LEFT JOIN
        public_exploits pe ON v.cve_id = pe.cve_id
    WHERE
        v.cvss_v3_score IS NOT NULL
    GROUP BY
        v.cve_id
    '''
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    # Clean data and handle missing values
    df.fillna({
        'cvss_v3_score': 0,
        'max_epss_score': 0,
        'has_public_exploit': 0
    }, inplace=True)
    
    # Create dummy variables for categorical features
    categorical_features = [
        'attack_vector', 'attack_complexity', 'privileges_required',
        'user_interaction', 'scope', 'confidentiality_impact', 
        'integrity_impact', 'availability_impact'
    ]
    
    for feature in categorical_features:
        # Skip if all values are NULL
        if df[feature].isna().all():
            continue
            
        dummies = pd.get_dummies(df[feature], prefix=feature, dummy_na=True)
        df = pd.concat([df, dummies], axis=1)
        df.drop(feature, axis=1, inplace=True)
    
    logger.info(f"Prepared dataset with {len(df)} rows and {len(df.columns)} columns")
    return df

def analyze_vulnerability_attributes(df):
    """Analyze vulnerability attributes that predict exploitation."""
    # Separate features and target
    X = df.drop(['cve_id', 'is_exploited'], axis=1)
    y = df['is_exploited']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # Train Random Forest model
    logger.info("Training Random Forest model...")
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # Evaluate model
    y_pred = model.predict(X_test)
    logger.info("Model performance:")
    logger.info("\n" + classification_report(y_test, y_pred))
    
    # Get feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    logger.info("Top 10 important features:")
    logger.info("\n" + str(feature_importance.head(10)))
    
    # Ensure output directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Save feature importance to CSV
    feature_importance.to_csv(os.path.join(OUTPUT_DIR, 'feature_importance.csv'), index=False)
    
    # Plot feature importance (top 15)
    plt.figure(figsize=(12, 8))
    plt.barh(feature_importance.head(15)['feature'], feature_importance.head(15)['importance'])
    plt.xlabel('Importance')
    plt.ylabel('Feature')
    plt.title('Top 15 Features for Predicting Vulnerability Exploitation')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, 'feature_importance.png'))
    
    logger.info(f"Feature importance plot saved to {os.path.join(OUTPUT_DIR, 'feature_importance.png')}")
    
    return feature_importance

def main():
    """Main function to analyze vulnerability attributes."""
    logger.info("Starting vulnerability attribution analysis...")
    
    # Prepare data
    df = prepare_data()
    
    # Analyze vulnerability attributes
    analyze_vulnerability_attributes(df)
    
    logger.info("Vulnerability attribution analysis complete")

if __name__ == "__main__":
    main()